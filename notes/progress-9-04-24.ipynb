{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Notes for Future Meeting (9/04/2024)\n",
    "Notes for a future meeting - currently playing around with classification !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib \n",
    "import pandas as pd \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(pathlib.Path.cwd().parents[0]/ \"src\" / \"classify\"))\n",
    "from prepare_data import load_metrics, create_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stories (Temp 1) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:] Loading data from human_metrics ...\n",
      "[INFO:] Loading data from ai_metrics ...\n"
     ]
    }
   ],
   "source": [
    "# data \n",
    "datapath = path.parents[0] / \"metrics\"\n",
    "stories1_df = load_metrics(datapath, dataset=\"stories\", temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3000\n",
      "           1       1.00      1.00      1.00      1500\n",
      "\n",
      "    accuracy                           1.00      4500\n",
      "   macro avg       1.00      1.00      1.00      4500\n",
      "weighted avg       1.00      1.00      1.00      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(enable_categorical=True, use_label_encoder=False, random_state=129)\n",
    "\n",
    "# all features\n",
    "splits = create_split(stories1_df, random_state=129, val_test_size=0.15, outcome_col=\"is_human\", verbose=False)\n",
    "\n",
    "clf.fit(splits[\"X_train\"], splits[\"y_train\"])\n",
    "\n",
    "# eval\n",
    "y_pred = clf.predict(splits[\"X_val\"])\n",
    "print(metrics.classification_report(splits[\"y_val\"], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      3000\n",
      "           1       0.86      0.67      0.75      1500\n",
      "\n",
      "    accuracy                           0.85      4500\n",
      "   macro avg       0.85      0.81      0.82      4500\n",
      "weighted avg       0.85      0.85      0.85      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = [\"doc_length\"]\n",
    "splits = create_split(stories1_df, random_state=129,\n",
    "                        val_test_size=0.15, \n",
    "                        outcome_col=\"is_human\", \n",
    "                        verbose=False, feature_cols=features\n",
    "                        )\n",
    "\n",
    "clf.fit(splits[\"X_train\"], splits[\"y_train\"])\n",
    "\n",
    "# eval\n",
    "y_pred = clf.predict(splits[\"X_val\"])\n",
    "print(metrics.classification_report(splits[\"y_val\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced Dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define funtion to check imbalance from splits dict \n",
    "def check_imbalance(datapath):\n",
    "    # create dict for saving imbalances\n",
    "    imbalance = {}\n",
    "\n",
    "    for dataset in [\"stories\", \"mrpc\", \"dailydialog\", \"dailymail_cnn\"]:\n",
    "        df = load_metrics(datapath, dataset=dataset, temp=1)\n",
    "        splits = create_split(df, random_state=129, val_test_size=0.15, outcome_col=\"is_human\", verbose=False)\n",
    "        \n",
    "        # dict with counts for each split\n",
    "        imbalance[dataset] = {'train': splits['y_train'].value_counts(),\n",
    "                              'val': splits['y_val'].value_counts(),\n",
    "                              'test': splits['y_test'].value_counts()}\n",
    "        \n",
    "    # convert to df \n",
    "    imbalance_df = pd.DataFrame.from_dict({(dataset, split): imbalance[dataset][split] for dataset in imbalance.keys() for split in imbalance[dataset].keys()}, orient='index')\n",
    "    imbalance_df.index.names = ['Dataset', 'Split']\n",
    "    imbalance_df.reset_index(inplace=True)\n",
    "\n",
    "    return imbalance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO:] Loading data from human_metrics ...\n",
      "[INFO:] Loading data from ai_metrics ...\n",
      "[INFO:] Loading data from human_metrics ...\n",
      "[INFO:] Loading data from ai_metrics ...\n",
      "[INFO:] Loading data from human_metrics ...\n",
      "[INFO:] Loading data from ai_metrics ...\n",
      "[INFO:] Loading data from human_metrics ...\n",
      "[INFO:] Loading data from ai_metrics ...\n",
      "          Dataset  Split      0     1\n",
      "0         stories  train  14000  7000\n",
      "1         stories    val   3000  1500\n",
      "2         stories   test   3000  1500\n",
      "3            mrpc  train  10920  5460\n",
      "4            mrpc    val   2340  1170\n",
      "5            mrpc   test   2340  1170\n",
      "6     dailydialog  train  14000  7000\n",
      "7     dailydialog    val   3000  1500\n",
      "8     dailydialog   test   3000  1500\n",
      "9   dailymail_cnn  train   8400  4200\n",
      "10  dailymail_cnn    val   1800   900\n",
      "11  dailymail_cnn   test   1800   900\n"
     ]
    }
   ],
   "source": [
    "imbalance_df = check_imbalance(datapath)\n",
    "print(imbalance_df) # where 0 is ai and 1 is human"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
